# Historical Context Assessment Questionnaire📝

A framework for identifying historical and structural bias in AI systems.

Each section contains five guiding questions designed for concise, evidence-based responses.

---

## 🔵 Section 1 – Domain and Application Context 🌐

1. **What is the domain and purpose of the AI system?**
2. **What documented patterns of explicit (formal) and implicit (systemic) discrimination exist in this domain?**
3. **Who has been historically excluded or misrepresented in related decision-making processes?**
4. **How might these historical dynamics still influence current data or model outputs?**
5. **What specific decisions will this system influence, and how could they affect access to opportunities or essential services?**

---

## 🟢 Section 2 – Data and Representation 📊

1. **What historical data sources inform this system, and how were they originally collected?**
2. **How have key variables been historically measured, and might those measurements encode bias?**
3. **How have relevant categories (e.g., gender, race, creditworthiness) been defined or changed over time?**
4. **Are there groups underrepresented or misrepresented in the available data?**
5. **What variables could act as proxies for sensitive or protected attributes?**

---

## 🟡 Section 3 – Technology and Amplification ⚙️

1. **How did previous technologies addressing similar functions create or reinforce inequities?**
2. **How could automation or algorithmic scaling amplify these historical biases?**
3. **What technical design choices (e.g., model type, feature selection) could increase bias risk?**
4. **What mitigation or audit mechanisms are built into the system to monitor fairness over time?**
5. **What unintended consequences might emerge from automation in this context?**

---

## 🔴 Section 4 – Impact and Accountability ✅

1. **Who is accountable for monitoring fairness and ethical compliance throughout the system’s lifecycle?**
2. **What metrics or evaluation frameworks will be used to assess fairness and inclusivity?**
3. **How will affected individuals or communities be able to contest or appeal automated decisions?**
4. **What transparency measures (e.g., documentation, explainability tools) are in place for stakeholders?**
5. **How will lessons learned from system audits be integrated into future model iterations?**
